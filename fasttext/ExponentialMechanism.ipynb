{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Mechanism\n",
    "This notebook contains the code used to reproduce the mechanism of (Yue et al., 2021). This code was used in Section 7 of the paper to compare it with our fixed mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.special import softmax\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# Add the main directory to sys.path to be able to import config\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from config import ROOT_DIR\n",
    "from utils.tools import rank_neighbors, compute_distances\n",
    "\n",
    "# PARAMS\n",
    "distance_metric = \"euclidean\"\n",
    "distances_dtype = np.float32 # Precision of the distances\n",
    "# !!! float32 (at least) needed to avoid overflow when computing probabilities\n",
    "\n",
    "fasttext_data_folderpath = ROOT_DIR\n",
    "# END PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(fasttext_data_folderpath, \"wiki.en.pkl\"), \"rb\") as f:\n",
    "    fasttext = pickle.load(f)\n",
    "\n",
    "vocab_embs = np.array(list(fasttext.values()))\n",
    "vocab_size = vocab_embs.shape[0]\n",
    "hidden_size = vocab_embs.shape[1]\n",
    "del fasttext # Save RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select *number_of_words* random words and rank their neighbors according to their distance with the word in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = 5000\n",
    "words_ids = np.random.randint(0, vocab_size, size=number_of_words)\n",
    "words_embs = vocab_embs[words_ids]\n",
    "\n",
    "# Get the distances between the selected words and the entire vocabulary\n",
    "distances = compute_distances(words_embs, vocab_embs, distance_metric, dtype=distances_dtype)\n",
    "\n",
    "# Also rank the entire vocabulary\n",
    "words_neighbors_ranked = rank_neighbors(words_embs, vocab_embs, distance_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise to the embeddings of the words following the $d_x$-privacy mechanism and count which neighbor was chosen, represented by its rank in the neighbor list of the initial word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.arange(0.5, 10.5, 0.5) # Parameter\n",
    "neighbor_counted_occurences = {}\n",
    "\n",
    "# Process epsilons in parallel\n",
    "n_workers = 1\n",
    "def process_epsilon(epsilon):\n",
    "    # Compute the probabilities\n",
    "    probabilities = softmax(-1/2*epsilon*distances, axis=-1)\n",
    "\n",
    "    # Sample one replacement for each word\n",
    "    noisy_word_ids = [np.random.choice(vocab_size, p=probabilities[i]) for i in range(number_of_words)]\n",
    "\n",
    "    # for all words_ids, get the rank k of noisy_word_ids[i] and increase a counter at index k\n",
    "    noisy_word_ids_ranks = words_neighbors_ranked[np.arange(number_of_words), noisy_word_ids] # This line, for all the elements i in the first dimension of words_neighbors_ranked, gets the particular value pointed by the index which is stored at noisy_word_ids[i]\n",
    "\n",
    "    noisy_word_ids_ranks_counted = Counter(noisy_word_ids_ranks)\n",
    "    return [noisy_word_ids_ranks_counted[k] for k in range(vocab_size)]\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "    results = list(executor.map(process_epsilon, epsilons))\n",
    "\n",
    "neighbor_counted_occurences = dict(zip(epsilons, results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are stored in *neighbor_counted_occurences*, which is a dictionary where the keys are integers representing the value of epsilon. The dictionary associates each epsilon with a list, where list[i] contains the number of times the i-th neighbor was chosen as the replacement of a word. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dx-privacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
